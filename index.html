<script>
    // Navigation Logic
    const steps = document.querySelectorAll('.step');
    const breadcrumbItems = document.querySelectorAll('.breadcrumb span');
    let currentStep = 0;

    const navigate = (direction) => {
        steps[currentStep].classList.remove('active');
        breadcrumbItems[currentStep].classList.remove('active');
        currentStep += direction;
        steps[currentStep].classList.add('active');
        breadcrumbItems[currentStep].classList.add('active');
    };

    document.querySelectorAll('.navigation button').forEach((button) => {
        button.addEventListener('click', (e) => {
            if (e.target.id.includes('next')) navigate(1);
            else if (e.target.id.includes('back')) navigate(-1);
        });
    });

    // File Upload Logic
    const fileInput = document.getElementById('fileUpload');
    const audioPreview = document.getElementById('audioPreview');

    document.getElementById('browseFiles').addEventListener('click', () => {
        const input = document.createElement('input');
        input.type = 'file';
        input.accept = 'audio/*';
        input.onchange = (e) => {
            const file = e.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audioPreview.src = url;
                audioPreview.load();
            }
        };
        input.click();
    });

    // Audio Recording Logic
    let mediaRecorder;
    const audioChunks = [];

    const startButton = document.getElementById('startRecording');
    const stopButton = document.getElementById('stopRecording');

    startButton.addEventListener('click', async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);

            mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                const url = URL.createObjectURL(audioBlob);
                audioPreview.src = url;
                audioPreview.load();
            };

            mediaRecorder.start();
            startButton.disabled = true;
            stopButton.disabled = false;
        } catch (error) {
            alert('Microphone access denied.');
        }
    });

    stopButton.addEventListener('click', () => {
        mediaRecorder.stop();
        startButton.disabled = false;
        stopButton.disabled = true;
    });

    // Chart Rendering Logic
    const renderChart = (chartId, type, data, options) => {
        const ctx = document.getElementById(chartId).getContext('2d');
        new Chart(ctx, { type, data, options });
    };

    renderChart('overallEngagementChart', 'doughnut', {
        labels: ['Engaged', 'Disengaged'],
        datasets: [{
            data: [75, 25],
            backgroundColor: ['#28A745', '#FF4C4C']
        }]
    });

    renderChart('sentimentChart', 'bar', {
        labels: ['Positive', 'Neutral', 'Negative'],
        datasets: [{
            data: [60, 30, 10],
            backgroundColor: ['#007BFF', '#FFC107', '#DC3545']
        }]
    });

    // Add remaining chart rendering logic...
</script>
